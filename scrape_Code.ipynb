{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mal Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making fuctipon for more detailed information\n",
    "\n",
    "<br> this info is found each anime's own webpage, thus it takes long\n",
    "\n",
    "such as:\n",
    "- anime type (TV/Movie/OVA)\n",
    "- premaried (season and year)\n",
    "- broadcast (day of week)\n",
    "- stuio responsible\n",
    "- duration\n",
    "- age rating (G, PG13, R, R+)\n",
    "- producers\n",
    "- Source (Manga, Original, LN)\n",
    "- Demograph (Shounen, Seinen)\n",
    "- Themes (Gore, Military, Psycological)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function scrapes certain data from a spesified anime, though the use of the MAL refence sequence\n",
    "\n",
    "\n",
    "def more_detail(mal_ref):\n",
    "      genreArray = []\n",
    "      themeArray = []\n",
    "\n",
    "      url_Ref = f\"https://myanimelist.net/anime/{mal_ref}\"\n",
    "\n",
    "      responseRef = requests.get(url_Ref).text\n",
    "      soupRef = BeautifulSoup(responseRef, 'html.parser')\n",
    "\n",
    "      time.sleep(2)\n",
    "\n",
    "      typeAni      = (soupRef.select_one('span:-soup-contains(\"Type:\")')).find_next().text\n",
    "\n",
    "      if typeAni == 'TV':\n",
    "            premiered  =   (soupRef.select_one('span:-soup-contains(\"Premiered:\")').find_next_sibling().text)\n",
    "            broadcast   = (soupRef.select_one('span:-soup-contains(\"Broadcast:\")').find_next_sibling(string=True).split(' '*4)[1].split(' at ')[0])\n",
    "     \n",
    "            duration    = (soupRef.select_one('span:-soup-contains(\"Duration:\")').find_next_sibling(string=True).split('  ')[1].split(' min. per')[0])\n",
    "\n",
    "      \n",
    "      elif typeAni == 'Movie':\n",
    " \n",
    "            premiered   = np.nan\n",
    "            broadcast   = np.nan\n",
    "                 \n",
    "            duration    = (soupRef.select_one('span:-soup-contains(\"Duration:\")').find_next_sibling(string=True)).split('  ')[1].split('.\\n')[0]\n",
    "\n",
    "\n",
    "      elif typeAni == 'ONA' or typeAni == 'OVA':\n",
    "            premiered   = np.nan\n",
    "            broadcast   = np.nan\n",
    "\n",
    "            duration    = (soupRef.select_one('span:-soup-contains(\"Duration:\")').find_next_sibling(string=True)).split('  ')[1].split('.\\n')[0].split('per epi')[0]\n",
    "            ## TODO: Fine tuning\n",
    "\n",
    "      elif typeAni == 'Special':\n",
    "            premiered   = np.nan\n",
    "            broadcast   = np.nan\n",
    "\n",
    "            duration    = (soupRef.select_one('span:-soup-contains(\"Duration:\")').find_next_sibling(string=True).split('  ')[1].split(' min. per')[0])\n",
    "\n",
    "      else:                         ## For Music types, hard to find only Music type\n",
    "            premiered   = np.nan\n",
    "            broadcast   = np.nan\n",
    "\n",
    "            duration    = (soupRef.select_one('span:-soup-contains(\"Duration:\")').find_next_sibling(string=True)).split('  ')[1]#.split('.\\n')[0]\n",
    "\n",
    "\n",
    "      \n",
    "      # TODO: Multiple Producers\n",
    "\n",
    "\n",
    "      status      = (soupRef.select_one('span:-soup-contains(\"Status:\")').find_next_sibling(string=True).split('  ')[1].split('\\n')[0])\n",
    "      producers   = (soupRef.select_one('span:-soup-contains(\"Producers:\")').find_next_sibling().text)                              ## Not done\n",
    "      studio      = (soupRef.select_one('span:-soup-contains(\"Studios:\")').find_next_sibling().text)\n",
    "      source      = (soupRef.select_one('span:-soup-contains(\"Source:\")').find_next_sibling(string=True).split('  ')[1].split('\\n')[0])\n",
    "      ageRating    = (soupRef.select_one('span:-soup-contains(\"Rating:\")').find_next_sibling(string=True).split(' ')[2])\n",
    "\n",
    "\n",
    "      # Gets all the differnt genees\n",
    "      #-------------------------\n",
    "\n",
    "      # Genre try and exexption\n",
    "      genre       = (soupRef.select_one('span:-soup-contains(\"Genre\")'))          #Works both\n",
    "      if genre != None:\n",
    "            try:\n",
    "                  genres = genre.find_next_siblings()\n",
    "                  for i in genres:\n",
    "                        genreArray.append(i.text)     \n",
    "      \n",
    "            ## THis is for single enties\n",
    "            except AttributeError:\n",
    "                  genre      =  genre.find_next_sibling()   # Gets one genre   \n",
    "\n",
    "                  genreArray.append(genre.text)\n",
    "      else:\n",
    "            genreArray.append( 'None')\n",
    "\n",
    "\n",
    "      #-------------------------------------------------\n",
    "      # Demograph try and exexption\n",
    "      demographic = (soupRef.select_one('span:-soup-contains(\"Demographic:\")'))\n",
    "\n",
    "      if demographic != None:\n",
    "            try:\n",
    "                  demographic = demographic.find_next_sibling().get_text()    \n",
    "\n",
    "            except AttributeError:\n",
    "                  demographic =  None\n",
    "                  ## if no value found give none\n",
    "      else:\n",
    "            demographic = 'None'\n",
    "\n",
    "\n",
    "      #-------------------------------------------------\n",
    "      # Theme try and exexption\n",
    "      theme      =  (soupRef.select_one('span:-soup-contains(\"Theme\")'))\n",
    "\n",
    "      if theme != None:\n",
    "            try:            \n",
    "                  themes = theme.find_next_siblings()\n",
    "                  for i in themes:\n",
    "                        themeArray.append(i.text)    \n",
    "\n",
    "            except AttributeError:\n",
    "                  theme      =  theme.find_next_sibling()\n",
    "                  themeArray.append(theme.text)\n",
    "      else:\n",
    "            themeArray.append( 'None')\n",
    "\n",
    "      \n",
    "      #-------------------------------------------------\n",
    "      # Only second enty eachtime\n",
    "      \n",
    "      genreArray = genreArray[::2]\n",
    "      themeArray = themeArray[::2]\n",
    "      #-------------------------\n",
    "\n",
    "\n",
    "      return status, premiered, broadcast, producers,studio, source, duration, ageRating, demographic, themeArray, genreArray\n",
    "      # return themeArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status, premiered, broadcast, producers, studio, source, duration, age_rating, demograph, theme, genres\n",
      "49387 :  ['Gore', 'Historical']\n",
      "39486 :  ['Gag Humor', 'Historical', 'Parody', 'Samurai']\n",
      "47917 :  ['CGDCT', 'Music']\n",
      "51535 :  ['Gore', 'Military', 'Survival']\n",
      "41467 :  ['None']\n"
     ]
    }
   ],
   "source": [
    "# Small Tests\n",
    "\n",
    "# okay = [49387,39486, 47917, 51535, 41467]\n",
    "\n",
    "# print('status, premiered, broadcast, producers, studio, source, duration, age_rating, demograph, theme, genres')\n",
    "# for i in okay:\n",
    "#     print(i , \": \" , more_detail(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main webscraping function\n",
    "\n",
    "Scrapes the data from the top anime main page\n",
    "\n",
    "scrapes data like:\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleListnew = []\n",
    "ratingListnew = []\n",
    "typeListnew = []\n",
    "startDateListnew = []\n",
    "endDateListnew = []\n",
    "episodeListnew = []\n",
    "membersListnew = []\n",
    "refenceListnew = []\n",
    "\n",
    "statusList = []\n",
    "premieredList = []\n",
    "broadcastList = []\n",
    "producerList = []\n",
    "studioList = []\n",
    "sourceList = []\n",
    "durationList = []\n",
    "ageRatingList = []\n",
    "\n",
    "demographList = []\n",
    "genreList = []\n",
    "themeList = []\n",
    "\n",
    "## 50 entries takes apprx -- 3m45s\n",
    "## 310 entries takes apprx -- 22m01s\n",
    "## 500 entries takes apprx -- 37m10s\n",
    "\n",
    "### Last score stuff at page: 13 750\n",
    "for page in range(0,500,50):\n",
    "    pages = f'https://myanimelist.net/topanime.php?limit={page}'\n",
    "\n",
    "    newResponse = requests.get(pages).text\n",
    "    soup = BeautifulSoup(newResponse, 'html.parser')\n",
    "\n",
    "    time.sleep(10)\n",
    "\n",
    "    \n",
    "    commoon_link = soup.find_all('tr', class_ = 'ranking-list')\n",
    "    \n",
    "    for elemment in commoon_link:\n",
    "        name = elemment.find('h3', attrs={'class':'hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3'})\n",
    "        score = elemment.find(class_='score ac fs14').text.split('\\n')[0]\n",
    "        \n",
    "        # # Have to deconstruct\n",
    "        aniInfo = elemment.find(class_ = 'information di-ib mt4').text.split(' '*8)\n",
    "        aniType = aniInfo[1].split(' ')[0]\n",
    "        members = aniInfo[3].split(' ')[0].replace(',', '')\n",
    "        \n",
    "        epiTotal = aniInfo[1].split(' ')[1].split('(')[1]\n",
    "\n",
    "        #TODO\n",
    "        # if epiTotal == '?':\n",
    "        #     print(0)\n",
    "              \n",
    "        \n",
    "        # # consentrate\n",
    "        airDate = aniInfo[2].split(' - ')[0]\n",
    "        airEnd = aniInfo[2].split(' - ')[1].split('\\n')[0]\n",
    "        \n",
    "        # ## URL Refense\n",
    "        ref = elemment.find('div', class_= 'hoverinfo').get('id').split('info')[1]\n",
    "\n",
    "        #-------------------------------\n",
    "\n",
    "        status, premiered, broadcast, producers,studio, source, duration, ageRating, demographic, themeArray, genreArray = more_detail(ref)\n",
    "        # status  = more_detail(ref)\n",
    "        \n",
    "        #-------------------------------\n",
    "\n",
    "        # Appending to Lists\n",
    "        titleListnew.append(name.text)          # correct\n",
    "        ratingListnew.append(float(score))      # correct\n",
    "        typeListnew.append(aniType)             # correct\n",
    "        episodeListnew.append((epiTotal))       # correct\n",
    "        startDateListnew.append(airDate)        # correct\n",
    "        endDateListnew.append(airEnd)           # correct\n",
    "        membersListnew.append(int(members))\n",
    "        refenceListnew.append(int(ref))\n",
    "        \n",
    "        # ###--Exta info lists ---\n",
    "        statusList.append(status)\n",
    "        premieredList.append(premiered)\n",
    "        broadcastList.append(broadcast)\n",
    "        producerList.append(producers)\n",
    "        studioList.append(studio)\n",
    "        sourceList.append(source)\n",
    "        durationList.append(duration)\n",
    "        ageRatingList.append(ageRating)\n",
    "        genreList.append(genreArray)\n",
    "\n",
    "        demographList.append(demographic)\n",
    "        themeList.append(themeArray)\n",
    "\n",
    "\n",
    "        # print(epiTotal)\n",
    "        # print(type(ref))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Dataframe with the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Type</th>\n",
       "      <th>AirDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>TotalEpi</th>\n",
       "      <th>Members</th>\n",
       "      <th>MAL Ref</th>\n",
       "      <th>Status</th>\n",
       "      <th>Premiered</th>\n",
       "      <th>Broadcast</th>\n",
       "      <th>Studio</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Age Ratingn</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Producer</th>\n",
       "      <th>Demograph</th>\n",
       "      <th>Themes</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Shingeki no Kyojin: The Final Season - Kankets...</td>\n",
       "      <td>9.21</td>\n",
       "      <td>Special</td>\n",
       "      <td>Mar 2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>309208</td>\n",
       "      <td>51535</td>\n",
       "      <td>Currently Airing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MAPPA</td>\n",
       "      <td>1 hr. 1</td>\n",
       "      <td>R</td>\n",
       "      <td>[Action, Drama, Suspense]</td>\n",
       "      <td>Production I.G</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>[Gore, Military, Survival]</td>\n",
       "      <td>Manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fullmetal Alchemist: Brotherhood</td>\n",
       "      <td>9.11</td>\n",
       "      <td>TV</td>\n",
       "      <td>Apr 2009</td>\n",
       "      <td>Jul 2010</td>\n",
       "      <td>64</td>\n",
       "      <td>3100193</td>\n",
       "      <td>5114</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Spring 2009</td>\n",
       "      <td>Sundays</td>\n",
       "      <td>Bones</td>\n",
       "      <td>24</td>\n",
       "      <td>R</td>\n",
       "      <td>[Action, Adventure, Drama, Fantasy]</td>\n",
       "      <td>Aniplex</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>[Military]</td>\n",
       "      <td>Manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bleach: Sennen Kessen-hen</td>\n",
       "      <td>9.09</td>\n",
       "      <td>TV</td>\n",
       "      <td>Oct 2022</td>\n",
       "      <td>Dec 2022</td>\n",
       "      <td>13</td>\n",
       "      <td>397875</td>\n",
       "      <td>41467</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Fall 2022</td>\n",
       "      <td>Tuesdays</td>\n",
       "      <td>Pierrot</td>\n",
       "      <td>24</td>\n",
       "      <td>R</td>\n",
       "      <td>[Action, Adventure, Fantasy]</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>[None]</td>\n",
       "      <td>Manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Steins;Gate</td>\n",
       "      <td>9.08</td>\n",
       "      <td>TV</td>\n",
       "      <td>Apr 2011</td>\n",
       "      <td>Sep 2011</td>\n",
       "      <td>24</td>\n",
       "      <td>2387240</td>\n",
       "      <td>9253</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Spring 2011</td>\n",
       "      <td>Wednesdays</td>\n",
       "      <td>White Fox</td>\n",
       "      <td>24</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>[Drama, Sci-Fi, Suspense]</td>\n",
       "      <td>Frontier Works</td>\n",
       "      <td>None</td>\n",
       "      <td>[Psychological, Time Travel]</td>\n",
       "      <td>Visual novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gintama°</td>\n",
       "      <td>9.07</td>\n",
       "      <td>TV</td>\n",
       "      <td>Apr 2015</td>\n",
       "      <td>Mar 2016</td>\n",
       "      <td>51</td>\n",
       "      <td>580202</td>\n",
       "      <td>28977</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>Spring 2015</td>\n",
       "      <td>Wednesdays</td>\n",
       "      <td>Bandai Namco Pictures</td>\n",
       "      <td>24</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>[Action, Comedy, Sci-Fi]</td>\n",
       "      <td>TV Tokyo</td>\n",
       "      <td>Shounen</td>\n",
       "      <td>[Gag Humor, Historical, Parody, Samurai]</td>\n",
       "      <td>Manga</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                              Title  Rating     Type  \\\n",
       "0     1  Shingeki no Kyojin: The Final Season - Kankets...    9.21  Special   \n",
       "1     2                   Fullmetal Alchemist: Brotherhood    9.11       TV   \n",
       "2     3                          Bleach: Sennen Kessen-hen    9.09       TV   \n",
       "3     4                                        Steins;Gate    9.08       TV   \n",
       "4     5                                           Gintama°    9.07       TV   \n",
       "\n",
       "    AirDate   EndDate TotalEpi  Members  MAL Ref            Status  \\\n",
       "0  Mar 2023      2023        2   309208    51535  Currently Airing   \n",
       "1  Apr 2009  Jul 2010       64  3100193     5114   Finished Airing   \n",
       "2  Oct 2022  Dec 2022       13   397875    41467   Finished Airing   \n",
       "3  Apr 2011  Sep 2011       24  2387240     9253   Finished Airing   \n",
       "4  Apr 2015  Mar 2016       51   580202    28977   Finished Airing   \n",
       "\n",
       "     Premiered   Broadcast                 Studio Duration Age Ratingn  \\\n",
       "0          NaN         NaN                  MAPPA  1 hr. 1           R   \n",
       "1  Spring 2009     Sundays                  Bones       24           R   \n",
       "2    Fall 2022    Tuesdays                Pierrot       24           R   \n",
       "3  Spring 2011  Wednesdays              White Fox       24       PG-13   \n",
       "4  Spring 2015  Wednesdays  Bandai Namco Pictures       24       PG-13   \n",
       "\n",
       "                                Genres        Producer Demograph  \\\n",
       "0            [Action, Drama, Suspense]  Production I.G   Shounen   \n",
       "1  [Action, Adventure, Drama, Fantasy]         Aniplex   Shounen   \n",
       "2         [Action, Adventure, Fantasy]        TV Tokyo   Shounen   \n",
       "3            [Drama, Sci-Fi, Suspense]  Frontier Works      None   \n",
       "4             [Action, Comedy, Sci-Fi]        TV Tokyo   Shounen   \n",
       "\n",
       "                                     Themes        Source  \n",
       "0                [Gore, Military, Survival]         Manga  \n",
       "1                                [Military]         Manga  \n",
       "2                                    [None]         Manga  \n",
       "3              [Psychological, Time Travel]  Visual novel  \n",
       "4  [Gag Humor, Historical, Parody, Samurai]         Manga  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiPage = pd.DataFrame(data={'Rank': range(1,len(titleListnew)+1),\n",
    "                               'Title':titleListnew,\n",
    "                                'Rating': ratingListnew,\n",
    "                                'Type': typeListnew,\n",
    "                                'AirDate': startDateListnew,        #TODO: Convert to datetime here?\n",
    "                                'EndDate': endDateListnew,\n",
    "                                \"TotalEpi\": episodeListnew,\n",
    "                                'Members' : membersListnew,\n",
    "                                'MAL Ref': refenceListnew,\n",
    "                                \n",
    "                                'Status' : statusList,                            \n",
    "                                'Premiered' : premieredList,                            \n",
    "                                'Broadcast' : broadcastList,\n",
    "                                'Studio' : studioList,                        \n",
    "                                'Duration' : durationList,                        \n",
    "                                'Age Ratingn' : ageRatingList,\n",
    "                                'Genres' : genreList,\n",
    "                                'Producer' : producerList,                            \n",
    "                                'Demograph' : demographList,                            \n",
    "                                'Themes' : themeList,                            \n",
    "                                'Source' : sourceList                        \n",
    "                                })\n",
    "\n",
    "multiPage.set_index('Rank').reset_index()\n",
    "# multiPage[['AirDate', 'EndDate']] = multiPage[['AirDate', 'EndDate']].apply(pd.to_datetime)\n",
    "# multiPage['AirDate'] = (pd.to_datetime(multiPage['AirDate']))\n",
    "\n",
    "\n",
    "multiPage.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving to csv for easier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiPage.to_excel('multiPages.xlsx', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cccf0148f04178e92e840c6e1071e5b6b8e5c15a27b56a3f7cc3cf5f13335e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
